{
   "cells": [
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Setup (must run cells marked *)\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "`pip install beautifulsoup4 bertopic flair keybert keyphrase_vectorizers libpff-python scikit-learn`"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "#### Imports*\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "import os\n",
            "import json\n",
            "import random\n",
            "import textwrap\n",
            "\n",
            "import pandas as pd"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "#### Get emails from PST file(s)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 4,
         "metadata": {},
         "outputs": [
            {
               "ename": "OSError",
               "evalue": "pypff_file_open: unable to open file. libcfile_file_open_wide_with_error_code: access denied to file: \\\\?\\c:\\projects\\email_classifier\\data.  libcfile_file_open_wide: unable to open file.  libbfio_file_io_handle_open: unable to open file: \\\\?\\c:\\projects\\email_classifier\\data.  libbfio_handle_open: unable to open handle.  libpff_file_open_file_io_handle: unable to open file IO handle.  libpff_file_open_wide: unable to open file: data.",
               "output_type": "error",
               "traceback": [
                  "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                  "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
                  "\u001b[1;32mc:\\projects\\email_classifier\\email_tools.ipynb Cell 6\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/projects/email_classifier/email_tools.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m pst_input \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/projects/email_classifier/email_tools.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m output_folder \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtest_psts\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/projects/email_classifier/email_tools.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m get_messages_from_pst(pst_input, output_folder)\n",
                  "File \u001b[1;32mc:\\projects\\email_classifier\\pst_extract.py:22\u001b[0m, in \u001b[0;36mget_messages_from_pst\u001b[1;34m(pst_path, output_folder)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misdir(output_folder):\n\u001b[0;32m     21\u001b[0m     os\u001b[39m.\u001b[39mmakedirs(output_folder, exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m---> 22\u001b[0m file_ \u001b[39m=\u001b[39m pypff\u001b[39m.\u001b[39;49mopen(pst_path)\n\u001b[0;32m     23\u001b[0m root \u001b[39m=\u001b[39m file_\u001b[39m.\u001b[39mget_root_folder()\n\u001b[0;32m     24\u001b[0m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m root\u001b[39m.\u001b[39msub_items:\n",
                  "\u001b[1;31mOSError\u001b[0m: pypff_file_open: unable to open file. libcfile_file_open_wide_with_error_code: access denied to file: \\\\?\\c:\\projects\\email_classifier\\data.  libcfile_file_open_wide: unable to open file.  libbfio_file_io_handle_open: unable to open file: \\\\?\\c:\\projects\\email_classifier\\data.  libbfio_handle_open: unable to open handle.  libpff_file_open_file_io_handle: unable to open file IO handle.  libpff_file_open_wide: unable to open file: data."
               ]
            }
         ],
         "source": [
            "from pst_extract import get_messages_from_pst\n",
            "\n",
            "# File path or folder with PSTs. \n",
            "pst_input = 'data'\n",
            "output_folder = 'test_psts'\n",
            "\n",
            "get_messages_from_pst(pst_input, output_folder)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "#### Specify folder contaning email text, one email per file*"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "email_folder = None"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Keyword Extraction"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "#### Setup\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "from keybert import KeyBERT\n",
            "from keyphrase_vectorizers import KeyphraseCountVectorizer\n",
            "from sklearn.feature_extraction.text import CountVectorizer\n",
            "\n",
            "kw_model = KeyBERT()\n",
            "\n",
            "def get_keywords(text, kwargs):\n",
            "    if kwargs.get('vectorizer'):\n",
            "        if kwargs['vectorizer'] == 'keyphrase':\n",
            "            kwargs['vectorizer'] = KeyphraseCountVectorizer()\n",
            "        else:\n",
            "            kwargs['vectorizer'] = CountVectorizer(\n",
            "                ngram_range=kwargs.get('keyphrase_ngram_range', (1, 1)),\n",
            "                stop_words=kwargs['stop_words']\n",
            "            )\n",
            "    keywords = kw_model.extract_keywords(text, **kwargs)\n",
            "    keywords = [x[0] for x in keywords]\n",
            "    print('KEYWORDS:\\n')\n",
            "    print('\\n'.join(keywords))"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "#### Extract keywords from a random or specified email (see KWARGS)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "email_path = os.path.join(email_folder, (random.choice(os.listdir(email_folder))))\n",
            "email = open(email_path, encoding='utf-8').read()\n",
            "\n",
            "KWARGS = {\n",
            "    'keyphrase_ngram_range': (1, 3), # Min, max word count for keywords\n",
            "    'use_mmr': True, # Increases diversity of keywords\n",
            "    'diversity': .5, # Set diversity between 0 and 1 if using MMR\n",
            "    'vectorizer': 'keyphrase', # (\"keyphrase\", True, False) How to represent document. Keyphrase vectorizer should be more coherent\n",
            "    'stop_words': 'english'\n",
            "}\n",
            "\n",
            "print(f'FILENAME: {email_path}\\n')\n",
            "print('TEXT:\\n ', \"\\n\".join(textwrap.wrap(email, 100)), '\\n')\n",
            "get_keywords(email, KWARGS)\n",
            "\n",
            "# Run on same email with different args\n",
            "# print()\n",
            "# KWARGS['vectorizer'] = True\n",
            "# get_keywords(email, KWARGS)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Topic Modeling"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "#### Setup"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "from bertopic import BERTopic\n",
            "from bertopic.representation import KeyBERTInspired, MaximalMarginalRelevance\n",
            "from bertopic.vectorizers import ClassTfidfTransformer"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "#### Get topics and view topic hierarchy (see comments)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Select subset or all emails in email folder\n",
            "slice_docs = (None, None)\n",
            "docs = [open(os.path.join(email_folder, filename), encoding='utf-8').read() for \n",
            "        filename in os.listdir(email_folder)[slice_docs[0]:slice_docs[1]]]\n",
            "\n",
            "# Document representations to chain and feed into topic model\n",
            "representations = [\n",
            "    KeyBERTInspired(), # Should make topics more coherent\n",
            "    MaximalMarginalRelevance(diversity=0.3), # Makes topics more diverse\n",
            "]\n",
            "\n",
            "ctfidf_model = ClassTfidfTransformer(reduce_frequent_words=True)\n",
            "\n",
            "topic_model = BERTopic(\n",
            "        representation_model=representations, # Representations (see above)\n",
            "        ctfidf_model=ctfidf_model,  # Prevents very frequent words in data from being candidate topics\n",
            "        nr_topics='auto' # Topic reduction. Set number of desired topics, 'auto' for auto-reduction, \n",
            "        # or None. Set to None if there aren't enough topic. \n",
            "        )\n",
            "topics, probabilities = topic_model.fit_transform(docs)\n",
            "hierarchical_topics = topic_model.hierarchical_topics(docs)\n",
            "topic_model.visualize_hierarchy(hierarchical_topics=hierarchical_topics)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "#### View topics as table"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "topic_model.get_topic_info()"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "#### Show docs per topic(s)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Select topic(s) by number (must be list). Get topic numbers from table or \n",
            "# labels in topic tree , ie. \"1_trees_grass_nature\" topic number is 1. \n",
            "topics_to_show = [0]\n",
            "# Show first n docs\n",
            "n_docs_to_show = 10\n",
            "# Show first n characters of each doc\n",
            "n_chars_per_doc = 500\n",
            "\n",
            "df = pd.DataFrame({\"Document\": docs, \"Topic\": topics})\n",
            "df = df.loc[df['Topic'].isin(topics_to_show)].head(n_docs_to_show)\n",
            "docs_ = df['Document'].to_list()\n",
            "random.shuffle(docs_)\n",
            "for i, doc in enumerate(docs_):\n",
            "    print(f'DOC {i + 1}\\n----------\\n')\n",
            "    print('\\n'.join(textwrap.wrap(doc[:n_chars_per_doc] + ' ...' if n_chars_per_doc else '')), '\\n')"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Get person-organization and sender/recipient Pairs"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "from get_pairs import get_keywords, get_entities, get_person_org_pairs,  get_all_sender_recipient_pairs\n",
            "\n",
            "# SPECIFY THIS\n",
            "DOCS_FOLDER = 'emails_small'\n",
            "#\n",
            "KW_PATH = 'kws.json'\n",
            "KW_BATCH_SIZE = None\n",
            "ENTITY_PATH = 'entities.json'\n",
            "RELEVANCE_PATH = 'relevance.json'\n",
            "RELEVANCE_LABEL = 'invoice synset only'\n",
            "REF_SYNSETS = ['invoice.n.01']\n",
            "ENTITY_PAIRS_PATH = 'person-org pairs.csv'\n",
            "TO_FROM_PAIRS_PATH = 'to_from_pairs.csv'\n",
            "RANKED_ENTITIES_PATH = 'ranked_entities.txt'\n",
            "KW_KWARGS = {'top_n': 10}\n",
            "GET_KWS = True\n",
            "GET_ENTITIES = True\n",
            "GET_PAIRS = True\n",
            "\n",
            "if GET_KWS:\n",
            "    get_keywords(KW_PATH,\n",
            "                  DOCS_FOLDER,\n",
            "                    KW_KWARGS,\n",
            "                      batch_size=KW_BATCH_SIZE)\n",
            "\n",
            "if GET_ENTITIES:\n",
            "    get_entities(\n",
            "        ENTITY_PATH,\n",
            "        DOCS_FOLDER,\n",
            "        KW_PATH,\n",
            "        RELEVANCE_PATH,\n",
            "        RELEVANCE_LABEL,\n",
            "        relevance_func_args={\n",
            "            'ref_synsets': REF_SYNSETS\n",
            "        })\n",
            "\n",
            "if GET_PAIRS:\n",
            "    person_org_pairs = get_person_org_pairs(\n",
            "        RELEVANCE_LABEL,\n",
            "        DOCS_FOLDER,\n",
            "        RELEVANCE_PATH,\n",
            "        ENTITY_PATH,\n",
            "        KW_PATH,\n",
            "        RANKED_ENTITIES_PATH\n",
            "    )\n",
            "    person_org_pairs.head(5000).to_csv(ENTITY_PAIRS_PATH)\n",
            "    to_from_pairs = get_all_sender_recipient_pairs(\n",
            "            RELEVANCE_PATH, DOCS_FOLDER, RELEVANCE_LABEL)\n",
            "    to_from_pairs.head(5000).to_csv(TO_FROM_PAIRS_PATH)"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "env",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.11.3"
      },
      "orig_nbformat": 4
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
