{
   "cells": [
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "\n",
            "### Email tools\n",
            "#### Setup (Must run cells marked *)\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "JS setup\n",
            "- `npm install pst-extractor` in process_pst folder.\n",
            "\n",
            "- Comment out lines 162-165 in *process_pst/node_modules/pst-extractor/dist/PSTFolder.class.js*: \n",
            "\n",
            "  ```\n",
            "  if ((emailRow && emailRow.itemIndex == -1) || !emailRow) {\n",
            "    // no more!\n",
            "    return null;\n",
            "  }\n",
            "  ```\n",
            "\n",
            "Process PST files\n",
            "- `node process_pst.js <input folder or file> <output folder>`\n",
            "\n",
            "Python dependencies\n",
            "\n",
            "- `pip install beautifulsoup4 bertopic flair keybert keyphrase_vectorizers scikit-learn`"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Imports *\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "import os\n",
            "import json\n",
            "import random\n",
            "import textwrap\n",
            "\n",
            "import pandas as pd"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Specify email folder *"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "email_folder =  None\n",
            "email_paths = []\n",
            "text = None\n",
            "for root, dirs, files in os.walk(email_folder):\n",
            "    for file in files:\n",
            "        if file.endswith('_Note.json'):\n",
            "            email_paths.append(os.path.join(root, file))"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "#### Keyword Extraction\n",
            "- Setup"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "from keybert import KeyBERT\n",
            "from keyphrase_vectorizers import KeyphraseCountVectorizer\n",
            "from sklearn.feature_extraction.text import CountVectorizer\n",
            "\n",
            "kw_model = KeyBERT()\n",
            "\n",
            "def get_keywords(text, kwargs):\n",
            "    if kwargs.get('vectorizer'):\n",
            "        if kwargs['vectorizer'] == 'keyphrase':\n",
            "            kwargs['vectorizer'] = KeyphraseCountVectorizer()\n",
            "        else:\n",
            "            kwargs['vectorizer'] = CountVectorizer(\n",
            "                ngram_range=kwargs.get('keyphrase_ngram_range', (1, 1)),\n",
            "                stop_words=kwargs['stop_words']\n",
            "            )\n",
            "    keywords = kw_model.extract_keywords(text, **kwargs)\n",
            "    keywords = [x[0] for x in keywords]\n",
            "    print('KEYWORDS:\\n')\n",
            "    print('\\n'.join(keywords))"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "- Extract keywords from a random or specified email (see KWARGS)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "while not text:\n",
            "    email_path = random.choice((email_paths))\n",
            "    text = json.load(open(email_path, encoding='utf-8')).get('bodyText')\n",
            "\n",
            "\n",
            "KWARGS = {\n",
            "    'keyphrase_ngram_range': (1, 3), # Min, max word count for keywords\n",
            "    'use_mmr': True, # Increases diversity of keywords\n",
            "    'diversity': .5, # Set diversity between 0 and 1 if using MMR\n",
            "    'vectorizer': 'keyphrase', # (\"keyphrase\", True, False) How to represent document. Keyphrase vectorizer should be more coherent\n",
            "    'stop_words': 'english'\n",
            "}\n",
            "\n",
            "print(f'FILENAME: {email_path}\\n')\n",
            "print('TEXT:\\n ', \"\\n\".join(textwrap.wrap(text, 100)), '\\n')\n",
            "get_keywords(text, KWARGS)\n",
            "\n",
            "# Run on same email with different args\n",
            "# print()\n",
            "# KWARGS['vectorizer'] = True\n",
            "# get_keywords(email, KWARGS)\n",
            "\n",
            "text = None"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "#### Topic Modeling"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "- Imports"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "from bertopic import BERTopic\n",
            "from bertopic.representation import KeyBERTInspired, MaximalMarginalRelevance\n",
            "from bertopic.vectorizers import ClassTfidfTransformer"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "- Get topics and view topic hierarchy (see comments)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Select subset or all emails in email folder\n",
            "slice_docs = (None, None)\n",
            "# docs = [open(os.path.join(email_folder, filename), encoding='utf-8').read() for \n",
            "#         filename in os.listdir(email_folder)[slice_docs[0]:slice_docs[1]]]\n",
            "docs = [json.load(open(path, encoding='utf-8')).get('bodyText', '') for \n",
            "        path in email_paths[slice_docs[0]:slice_docs[1]]]\n",
            "docs = [doc for doc in docs if doc.strip()]\n",
            "# Document representations to chain and feed into topic model\n",
            "representations = [\n",
            "    KeyBERTInspired(), # Should make topics more coherent\n",
            "    MaximalMarginalRelevance(diversity=0.3), # Makes topics more diverse\n",
            "]\n",
            "\n",
            "ctfidf_model = ClassTfidfTransformer(reduce_frequent_words=True)\n",
            "\n",
            "topic_model = BERTopic(\n",
            "        representation_model=representations, # Representations (see above)\n",
            "        ctfidf_model=ctfidf_model,  # Prevents very frequent words in data from being candidate topics\n",
            "        nr_topics='auto' # Topic reduction. Set number of desired topics, 'auto' for auto-reduction, \n",
            "        # or None. Set to None if there aren't enough topic. \n",
            "        )\n",
            "topics, probabilities = topic_model.fit_transform(docs)\n",
            "hierarchical_topics = topic_model.hierarchical_topics(docs)\n",
            "topic_model.visualize_hierarchy(hierarchical_topics=hierarchical_topics)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "- View topics as table"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "topic_model.get_topic_info()"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "- Show docs per topic(s)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Select topic(s) by number (must be list). Get topic numbers from table or \n",
            "# labels in topic tree , ie. \"1_trees_grass_nature\" topic number is 1. \n",
            "topics_to_show = [0]\n",
            "# Show first n docs\n",
            "n_docs_to_show = 10\n",
            "# Show first n characters of each doc\n",
            "n_chars_per_doc = 500\n",
            "\n",
            "df = pd.DataFrame({\"Document\": docs, \"Topic\": topics})\n",
            "df = df.loc[df['Topic'].isin(topics_to_show)].head(n_docs_to_show)\n",
            "docs_ = df['Document'].to_list()\n",
            "random.shuffle(docs_)\n",
            "for i, doc in enumerate(docs_):\n",
            "    print(f'DOC {i + 1}\\n----------\\n')\n",
            "    print('\\n'.join(textwrap.wrap(doc[:n_chars_per_doc] + ' ...' if n_chars_per_doc else '')), '\\n')"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "#### Get vendors, person-org and sender-recipient pairs"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "from collections import Counter\n",
            "from get_kws_and_entities import get_keywords, get_entities, get_person_org_pairs,  get_all_sender_recipient_pairs\n",
            "\n",
            "# Specify DOCS_FOLDER. Don't need to run \"Specify email folder\" cell for this. \n",
            "DOCS_FOLDER = email_folder\n",
            "OUTPUT = None\n",
            "#\n",
            "KW_PATH = f'{OUTPUT}/kws.json'\n",
            "KW_BATCH_SIZE = None\n",
            "ENTITY_PATH = f'{OUTPUT}/entities.json'\n",
            "RELEVANCE_PATH = f'{OUTPUT}/relevance.json'\n",
            "RELEVANCE_LABEL = 'invoice synset only'\n",
            "REF_SYNSETS = ['invoice.n.01']\n",
            "ENTITY_PAIRS_PATH = f'{OUTPUT}/person-org pairs.csv'\n",
            "ORGS_PATH = f'{OUTPUT}/vendors.csv'\n",
            "TO_FROM_PAIRS_PATH = f'{OUTPUT}/to_from_pairs.csv'\n",
            "RANKED_ENTITIES_PATH = f'{OUTPUT}/ranked_entities.txt'\n",
            "KW_KWARGS = {'top_n': 10}\n",
            "GET_KWS = True\n",
            "GET_ENTITIES = True\n",
            "GET_PAIRS = True\n",
            "\n",
            "if not os.path.isdir(OUTPUT):\n",
            "    os.makedirs(OUTPUT)\n",
            "\n",
            "if GET_KWS:\n",
            "    get_keywords(KW_PATH,\n",
            "                  DOCS_FOLDER,\n",
            "                    KW_KWARGS,\n",
            "                      batch_size=KW_BATCH_SIZE)\n",
            "\n",
            "if GET_ENTITIES:\n",
            "    get_entities(\n",
            "        ENTITY_PATH,\n",
            "        DOCS_FOLDER,\n",
            "        KW_PATH,\n",
            "        RELEVANCE_PATH,\n",
            "        RELEVANCE_LABEL,\n",
            "        relevance_func_args={\n",
            "            'ref_synsets': REF_SYNSETS\n",
            "        })\n",
            "\n",
            "if GET_PAIRS:\n",
            "    person_org_pairs = get_person_org_pairs(\n",
            "        RELEVANCE_LABEL,\n",
            "        RELEVANCE_PATH,\n",
            "        ENTITY_PATH,\n",
            "        KW_PATH,\n",
            "        RANKED_ENTITIES_PATH\n",
            "    )\n",
            "    person_org_pairs.head(5000).to_csv(ENTITY_PAIRS_PATH)\n",
            "    orgs = Counter(person_org_pairs.loc[:, 'org'])\n",
            "    orgs = {'org': list(orgs.keys()), 'count': list(orgs.values())}\n",
            "    orgs = pd.DataFrame(orgs)\n",
            "    orgs.sort_values(by='count', ascending=False).to_csv(ORGS_PATH)\n",
            "    to_from_pairs = get_all_sender_recipient_pairs(\n",
            "            RELEVANCE_PATH, RELEVANCE_LABEL)\n",
            "    to_from_pairs.head(5000).to_csv(TO_FROM_PAIRS_PATH)"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "env",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.11.3"
      },
      "orig_nbformat": 4
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
